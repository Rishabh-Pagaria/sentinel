{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c962d28",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn pandas torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6877f",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75425ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/rpaga/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb46ce6",
   "metadata": {},
   "source": [
    "## 3. Import Libraries and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Check GPU\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf592ebd",
   "metadata": {},
   "source": [
    "## 4. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f69750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter data from Google Drive\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/phishing_project/processed_phishing_data.csv\")\n",
    "df = df[[\"text\", \"label\"]].dropna()\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "# Filter out extremely long texts (corrupted data)\n",
    "original_len = len(df)\n",
    "df['text_len'] = df['text'].str.len()\n",
    "df = df[df['text_len'] < 100000]\n",
    "df = df.drop(columns=['text_len'])\n",
    "print(f\"Filtered out {original_len - len(df)} samples with >100K characters\")\n",
    "\n",
    "# Split data: 60% train, 20% validation, 20% test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "eval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
    "print(f\"Train: {len(train_df)}, Eval: {len(eval_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf27fda",
   "metadata": {},
   "source": [
    "## 5. Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7242e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class\n",
    "class SimpleDataset(TorchDataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6363858",
   "metadata": {},
   "source": [
    "## 6. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b0103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model from HuggingFace\n",
    "print(\"Loading model from HuggingFace...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=2)\n",
    "print(\"✓ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f3c00",
   "metadata": {},
   "source": [
    "## 7. Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets with memory-efficient batching\n",
    "def build_dataset(df, tokenizer, max_length=512):\n",
    "    texts = df[\"text\"].tolist()\n",
    "    labels = df[\"label\"].tolist()\n",
    "    \n",
    "    print(f\"Tokenizing {len(texts)} samples in batches...\")\n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    \n",
    "    # Smaller batch size to avoid RAM spikes\n",
    "    batch_size = 50\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"  Processed {i}/{len(texts)} samples...\")\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_enc = tokenizer(batch_texts, truncation=True, max_length=max_length, padding=False)\n",
    "        all_input_ids.extend(batch_enc['input_ids'])\n",
    "        all_attention_mask.extend(batch_enc['attention_mask'])\n",
    "    \n",
    "    encodings = {'input_ids': all_input_ids, 'attention_mask': all_attention_mask}\n",
    "    print(f\"✓ Tokenization complete: {len(labels)} samples\")\n",
    "    return SimpleDataset(encodings, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153e0ca",
   "metadata": {},
   "source": [
    "## 8. Build Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = build_dataset(train_df, tokenizer)\n",
    "eval_ds = build_dataset(eval_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd8c0c",
   "metadata": {},
   "source": [
    "## 9. Define Collator and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd65589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collator for dynamic padding\n",
    "def collate_fn(batch):\n",
    "    max_len = max(len(x[\"input_ids\"]) for x in batch)\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "    \n",
    "    for item in batch:\n",
    "        ids = item[\"input_ids\"]\n",
    "        attn = item[\"attention_mask\"]\n",
    "        pad_len = max_len - len(ids)\n",
    "        \n",
    "        input_ids.append(ids + [0] * pad_len)\n",
    "        attention_masks.append(attn + [0] * pad_len)\n",
    "        labels.append(item[\"labels\"])\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"attention_mask\": torch.tensor(attention_masks),\n",
    "        \"labels\": torch.tensor(labels)\n",
    "    }\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
    "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d578ce43",
   "metadata": {},
   "source": [
    "## 10. Configure Training\n",
    "\n",
    "### Fine-tuning Parameters:\n",
    "- **Base Model**: microsoft/deberta-v3-base (184M parameters)\n",
    "- **Batch Size**: 8 per device (effective batch size: 16 with gradient accumulation)\n",
    "- **Learning Rate**: 2e-5 (standard for transformer fine-tuning)\n",
    "- **Epochs**: 3\n",
    "- **Weight Decay**: 0.01 (regularization)\n",
    "- **Optimization**: AdamW optimizer (default in Transformers)\n",
    "- **Mixed Precision**: FP16 for faster training and lower memory\n",
    "- **Max Sequence Length**: 512 tokens (DeBERTa maximum)\n",
    "- **Classification Head**: 2 labels (phishing vs legitimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ad348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments - save to Google Drive\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/phishing_project/deberta-phishing\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,  # Effective batch size = 16\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    report_to=[],\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    save_total_limit=2,  # Keep only 2 best checkpoints\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e607b",
   "metadata": {},
   "source": [
    "## 11. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e16489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print(\"Training starting...\")\n",
    "trainer.train()\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86efc0fc",
   "metadata": {},
   "source": [
    "## 12. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\n=== Final Test Set Evaluation ===\")\n",
    "test_ds = build_dataset(test_df, tokenizer)\n",
    "test_results = trainer.evaluate(test_ds)\n",
    "print(f\"Test Accuracy:  {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Test Precision: {test_results['eval_precision']:.4f}\")\n",
    "print(f\"Test F1:        {test_results['eval_f1']:.4f}\")\n",
    "print(f\"Test Loss:      {test_results['eval_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2aa2e6",
   "metadata": {},
   "source": [
    "## 13. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model to Google Drive\n",
    "save_path = \"/content/drive/MyDrive/phishing_project/deberta-phishing-final\"\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"\\n✓ Model saved to Google Drive at: {save_path}\")\n",
    "print(\"Even if Colab disconnects, your model is safe in Google Drive!\")\n",
    "print(\"\\nTo use locally:\")\n",
    "print(\"1. Download the 'deberta-phishing-final' folder from Drive\")\n",
    "print(\"2. Extract to 'artifacts/encoders/deberta-v3-base'\")\n",
    "print(\"3. Use encoder.load() for predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
