#!/usr/bin/env python3
"""
Prepare dataset for Vertex AI fine-tuning by converting JSONL to required format.
"""

import json
import argparse
from typing import List, Dict
import os
from google.cloud import storage

def format_example(example: Dict) -> Dict:
    """Format a single example for fine-tuning"""
    # Extract email text and true label
    input_text = example["input"].replace("EMAIL: ", "")
    label = example["output"]["label"]
    
    # Create the expected output format
    output = {
        "label": label,
        "confidence": 1.0 if label == "phish" else 0.0,
        "tactics": [],  # Will be inferred by model
        "evidence": [],  # Will be inferred by model
        "user_tip": ""  # Will be generated by model
    }
    
    # Format for Vertex AI
    return {
        "input_text": input_text,
        "output_json": json.dumps(output)
    }

def prepare_dataset(input_jsonl: str, output_jsonl: str):
    """Convert dataset to Vertex AI format"""
    examples = []
    
    # Read input JSONL
    with open(input_jsonl, 'r') as f:
        for line in f:
            example = json.loads(line.strip())
            formatted = format_example(example)
            examples.append(formatted)
    
    # Write formatted examples
    with open(output_jsonl, 'w') as f:
        for example in examples:
            f.write(json.dumps(example) + '\n')

def upload_to_gcs(local_path: str, bucket_name: str, blob_name: str):
    """Upload file to Google Cloud Storage"""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    blob.upload_from_filename(local_path)
    print(f"File {local_path} uploaded to gs://{bucket_name}/{blob_name}")

def main():
    parser = argparse.ArgumentParser(description="Prepare dataset for Vertex AI fine-tuning")
    parser.add_argument("--input", required=True, help="Input JSONL file")
    parser.add_argument("--output", required=True, help="Output JSONL file")
    parser.add_argument("--bucket", required=True, help="GCS bucket name")
    args = parser.parse_args()
    
    # Convert dataset
    prepare_dataset(args.input, args.output)
    
    # Upload to GCS
    blob_name = os.path.basename(args.output)
    upload_to_gcs(args.output, args.bucket, f"training_data/{blob_name}")

if __name__ == "__main__":
    main()